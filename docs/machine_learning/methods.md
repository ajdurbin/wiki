Need standard set of techniques to do when approaching new problems.

# Methods #

* regression
* logistic regression
* lasso
* ridge
* elastic net
* cart
* random forest
* adaboost
* extratrees
* gcForest
* k means
* dbscan
* pcr
* pca
* svm
* wls
* feature importance plots
* roc/auc plots
* isolation forest
* manifold learning/tsne
* dbscan
* hierarchical clustering
* boosted forest
* multidimensional scaling
* agglomerative/hierarchical

# Scoring Metrics #
Different ways to score if groups/unbalanced classes

#Different Shuffling Methods #
How to split data properly for grid searching model to be used over before training and then testing?

# Salad #
- sklearn face data examples
- pca/kmeans/agglomerative clustering use scree plots
- dbscan isomap
- other metrics for clustering besides rand
- over vs undersampling with imbalanced classes
- Dood: set of hyperparameters selected randomly, train N models, select M best, add jitter, add more randomly generated and iterate to automatically choose model architecture
- Crossover: because not obvious to combine models with different number of layers to form child
- costline automation genetic algorithms
- dimension reduction then fit classifier/regression examples
- anomaly detection
- lstm
- isolation forest
- nmf
- reddit machine learning wiki
- <https://distill.pub/2016/misread-tsne/> how to use t-sne effectively
